# IndexTTS2 Rust Rewrite - Task Plan

## Phase 1: Foundation [COMPLETE]

### Config & Setup
- [x] **P1.1** Implement `src/config/model_config.rs` - YAML config parsing with serde
  - Parse `checkpoints/config.yaml` structure
  - Create `GptConfig`, `S2MelConfig`, `VocoderConfig` structs
  - Context7: `Context7:resolve-library-id "serde yaml"`

### Text Processing
- [x] **P1.2** Implement `src/text/tokenizer.rs` - BPE tokenization
  - Use HuggingFace tokenizers crate
  - Load tokenizer from JSON file, encode/decode text
  - Added: encode_for_gpt(), vocab_size(), set_special_tokens()

- [x] **P1.3** Implement `src/text/normalizer.rs` - Text normalization
  - Number to words conversion (integers, decimals, negatives)
  - Abbreviation expansion (Dr., Mr., etc.)
  - Punctuation and whitespace normalization

- [x] **P1.4** Implement `src/text/segmenter.rs` - Sentence segmentation
  - Split at sentence boundaries (. ! ? and Chinese equivalents)
  - Respect max_tokens limit with fallback to clause/word boundaries
  - segment_text(), segment_text_string(), segment_mixed_text()

### Audio I/O
- [x] **P1.5** Implement `src/audio/loader.rs` - Audio file loading
  - Support WAV, MP3, FLAC, OGG via symphonia
  - Automatic resampling to target rate
  - Mono conversion from stereo

- [x] **P1.6** Implement `src/audio/resampler.rs` - Sample rate conversion
  - High-quality sinc interpolation via rubato
  - Chunked processing for long audio
  - Convenience methods: resample_to_16k(), resample_to_22k()

- [x] **P1.7** Implement `src/audio/mel.rs` - Mel spectrogram
  - FFT via rustfft with cached planner
  - 80 mel bands, librosa-compatible
  - new_default() for IndexTTS2 parameters, compute_transposed()

- [x] **P1.8** Implement `src/audio/output.rs` - Audio playback
  - WAV file saving (16-bit PCM, 32-bit float)
  - Real-time playback via cpal
  - StreamingPlayer for real-time TTS output

---

## Phase 2: Core Encoders [COMPLETE]

### Semantic Encoder
- [x] **P2.1** Implement `src/models/semantic/wav2vec_bert.rs`
  - Wav2Vec-BERT 2.0 feature extraction
  - Self-attention, feed-forward, encoder layers
  - Layer 17 extraction with normalization

- [x] **P2.2** Implement `src/models/semantic/codec.rs`
  - Vector quantization with 8192 codebook
  - L2 distance nearest neighbor search
  - Projection layers for hidden_size/codebook_dim conversion

### Speaker Encoder
- [x] **P2.3** Implement `src/models/speaker/campplus.rs`
  - CAMPPlus speaker embedding (192-dim output)
  - D-TDNN architecture with dense connections
  - Statistics pooling (mean + std)

### Emotion (Optional)
- [x] **P2.4** Implement `src/models/emotion/matrix.rs`
  - 8 emotion categories matrix lookup
  - Emotion blending with configurable alpha
  - Category-based and global index access

---

## Phase 3: GPT Generation [COMPLETE]

### Conformer Encoder
- [x] **P3.1** Implement `src/models/gpt/conformer.rs`
  - Feed-forward + Self-attention + Convolution + Feed-forward (Macaron-style)
  - Swish activation, GLU gating
  - Configurable blocks, heads, kernel size

### Perceiver Resampler
- [x] **P3.2** Implement `src/models/gpt/perceiver.rs`
  - Learned latent queries for fixed-length conditioning
  - Cross-attention to encoder outputs
  - Self-attention between latents

### KV Cache
- [x] **P3.3** Implement `src/models/gpt/kv_cache.rs`
  - Per-layer key-value caching
  - Efficient incremental append
  - CachedAttention with causal masking

### Unified Voice Model
- [x] **P3.4** Implement `src/models/gpt/unified_voice.rs`
  - GPT-2 decoder: 1280 dim, 24 layers, 20 heads
  - Text + mel embeddings, positional encoding
  - Conformer + Perceiver conditioning integration

### Generation Loop
- [x] **P3.5** Implement `src/models/gpt/generation.rs`
  - Autoregressive generation with KV cache
  - Top-k/top-p sampling, temperature
  - Repetition penalty, stop token detection

---

## Phase 4: Synthesis [COMPLETE]

### Length Regulator
- [x] **P4.1** Implement `src/models/s2mel/length_regulator.rs`
  - Mel code to target length expansion
  - Duration predictor with ConvBlock layers
  - Reference: `indextts/s2mel/modules/length_regulator.py`

### Diffusion Transformer
- [x] **P4.2** Implement `src/models/s2mel/dit.rs`
  - DiT: 13 layers, 512 hidden, 8 heads
  - AdaLN conditioning, UViT skip connections
  - Sinusoidal time embeddings, multi-head attention
  - Reference: `indextts/s2mel/modules/diffusion_transformer.py`

### Flow Matching
- [x] **P4.3** Implement `src/models/s2mel/flow_matching.rs`
  - CFM with 25 steps, cfg_rate=0.7
  - Euler and Heun ODE solvers
  - Classifier-free guidance support
  - Reference: `indextts/s2mel/modules/flow_matching.py`

### BigVGAN Vocoder
- [x] **P4.4** Implement `src/models/vocoder/bigvgan.rs`
  - BigVGAN v2 22kHz 80-band (256x upsampling)
  - Snake anti-aliased activation
  - Multi-resolution fusion (MRF) blocks
  - Reference: `indextts/BigVGAN/bigvgan.py`

---

## Phase 5: Integration [COMPLETE]

### Pipeline
- [x] **P5.1** Implement `src/inference/pipeline.rs`
  - IndexTTS2 struct wiring all components
  - InferenceConfig for runtime settings
  - infer() and infer_with_emotion() methods
  - Reference: `indextts/infer_v2.py`

### Streaming
- [x] **P5.2** Implement `src/inference/streaming.rs`
  - StreamingSynthesizer for chunk-based synthesis
  - Async audio generation with channels
  - Callback-based streaming interface
  - Real-time playback support

### CLI
- [x] **P5.3** Complete `src/main.rs`
  - Full clap argument parsing
  - --text, --speaker, --emotion, --output flags
  - --temperature, --top-k, --top-p sampling params
  - Progress bars with indicatif

### Tests
- [x] **P5.4** Integration tests in `tests/`
  - Full model chain test (placeholder weights)
  - Component initialization tests
  - Text/audio processing tests
  - Config parsing validation

---

## Phase 6: Debug & Validate [COMPLETE]

### Reference Data Generation
- [x] **P6.1** Create `debug/dump_python.py` script
  - Hook into Python IndexTTS model
  - Save intermediate tensors at each layer as .npy files
  - Mock data generation for testing without Python deps

- [x] **P6.2** Generate golden reference data
  - TensorDumper class for organized output
  - Subdirectories: input/, encoders/, gpt/, synthesis/, output/
  - Supports both real model and mock data

### Rust Validation Harness
- [x] **P6.3** Implement `src/debug/mod.rs` and `src/debug/validator.rs`
  - Custom NPY loader (no external deps)
  - Shape/value comparison with configurable tolerance
  - ValidationResult with detailed metrics

- [x] **P6.4** Create debug CLI: `src/bin/debug_validate.rs`
  - `--component` flag: all, tokenizer, mel, speaker, semantic, gpt, s2mel, vocoder, full
  - `--golden-dir` for reference data path
  - `--verbose` for detailed diff output
  - `--atol`/`--rtol` tolerance configuration

### Layer-by-Layer Validation
- [x] **P6.5** Validate text processing
  - Tokenizer validation function
  - Integer array comparison for token IDs

- [x] **P6.6** Validate audio processing
  - Mel spectrogram validation
  - Configurable tolerance (default 1e-4)

- [x] **P6.7** Validate encoders
  - Speaker encoder (CAMPPlus) validation
  - Semantic encoder (Wav2Vec-BERT) validation

- [x] **P6.8** Validate GPT forward pass
  - Layer 0, 12, 23 output validation
  - Mel codes comparison

- [x] **P6.9** Validate synthesis
  - Length regulator validation
  - DiT step validation (steps 0, 12, 24)
  - Flow matching final output

### Fix & Document
- [x] **P6.10** Create `FIXES.md` documenting all corrections
  - Architecture overview
  - Implementation notes per phase
  - Known issues and workarounds
  - Validation checklist
  - Performance metrics template

- [x] **P6.11** End-to-end audio validation
  - Full pipeline validation function
  - Component creation verification
  - Audio output validation structure

---

## Completion Tracking

**Phase 1:** 8/8 complete ‚úÖ
**Phase 2:** 4/4 complete ‚úÖ
**Phase 3:** 5/5 complete ‚úÖ
**Phase 4:** 4/4 complete ‚úÖ
**Phase 5:** 4/4 complete ‚úÖ
**Phase 6:** 11/11 complete ‚úÖ

**Total:** 36/36 tasks complete (100%) üéâ

## Phases 1-6 Complete!

Core implementation done:
- Text processing (tokenizer, normalizer, segmenter)
- Audio I/O (loader, resampler, mel spectrogram, output)
- Encoders (Wav2Vec-BERT, CAMPPlus, Emotion Matrix)
- GPT Generation (Conformer, Perceiver, KV-Cache, UnifiedVoice)
- Synthesis (Length Regulator, DiT, Flow Matching, BigVGAN)
- Integration (Pipeline, Streaming, CLI, Tests)
- Debug & Validation (Python dump, NPY loader, Validator, Debug CLI)

---

## Remaining Phases

### Phase 7: Weight Loading [PENDING]
See: `@fix_plan_phase7.md`
- Convert PyTorch .pth to safetensors
- Implement weight loading in Rust
- 8 tasks

### Phase 8: BigVGAN Vocoder [PENDING]
See: `@fix_plan_phase8.md`
- Download BigVGAN from HuggingFace
- Integrate vocoder with pipeline
- 7 tasks

### Phase 9: Testing & Polish [PENDING]
See: `@fix_plan_phase9.md`
- Fix test compilation
- Add comprehensive tests
- Documentation and cleanup
- 12 tasks

---

## Overall Progress

**Phases 1-6:** 36/36 complete ‚úÖ
**Phase 7:** 0/8 complete ‚è≥
**Phase 8:** 0/7 complete ‚è≥
**Phase 9:** 0/12 complete ‚è≥

**Total:** 36/63 tasks complete (57%)

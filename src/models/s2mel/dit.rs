//! Diffusion Transformer (DiT) for mel spectrogram synthesis
//!
//! Implements a transformer-based denoising model with:
//! - Time embedding for diffusion timesteps
//! - Style conditioning from speaker embeddings
//! - UViT-style skip connections between layers
//! - AdaLN (Adaptive Layer Normalization) for conditioning

use anyhow::Result;
use candle_core::{Device, Tensor, DType, D};
use candle_nn::{Linear, Module, LayerNorm};
use std::path::Path;

/// DiT configuration
#[derive(Clone)]
pub struct DiffusionTransformerConfig {
    /// Hidden dimension
    pub hidden_dim: usize,
    /// Number of attention heads
    pub num_heads: usize,
    /// Number of transformer layers
    pub depth: usize,
    /// Input channels (mel bands)
    pub in_channels: usize,
    /// Whether to use style conditioning
    pub style_condition: bool,
    /// Style embedding dimension
    pub style_dim: usize,
    /// Whether to use UViT skip connections
    pub uvit_skip_connection: bool,
    /// Content dimension
    pub content_dim: usize,
    /// Block size for attention
    pub block_size: usize,
    /// Dropout probability
    pub dropout: f32,
}

impl Default for DiffusionTransformerConfig {
    fn default() -> Self {
        Self {
            hidden_dim: 512,
            num_heads: 8,
            depth: 13,
            in_channels: 80,
            style_condition: true,
            style_dim: 192,
            uvit_skip_connection: true,
            content_dim: 512,
            block_size: 8192,
            dropout: 0.1,
        }
    }
}

/// Sinusoidal time embedding
fn sinusoidal_embedding(timesteps: &Tensor, dim: usize, device: &Device) -> Result<Tensor> {
    let half_dim = dim / 2;
    let emb_scale = -(10000.0f32.ln()) / (half_dim as f32 - 1.0);

    // Create frequency bands
    let freqs: Vec<f32> = (0..half_dim)
        .map(|i| (i as f32 * emb_scale).exp())
        .collect();
    let freqs = Tensor::from_slice(&freqs, (1, half_dim), device)?;

    // timesteps: (batch,) -> (batch, 1)
    let timesteps = timesteps.unsqueeze(1)?;
    let timesteps = timesteps.to_dtype(DType::F32)?;

    // Compute sin and cos embeddings
    let args = timesteps.broadcast_mul(&freqs)?;
    let sin_emb = args.sin()?;
    let cos_emb = args.cos()?;

    // Concatenate sin and cos
    Tensor::cat(&[sin_emb, cos_emb], 1).map_err(Into::into)
}

/// Time embedding MLP
struct TimestepEmbedding {
    linear1: Linear,
    linear2: Linear,
    dim: usize,
}

impl TimestepEmbedding {
    fn new(dim: usize, device: &Device) -> Result<Self> {
        let inner_dim = dim * 4;

        let w1 = Tensor::randn(0.0f32, 0.02, (inner_dim, dim), device)?;
        let b1 = Tensor::zeros((inner_dim,), DType::F32, device)?;
        let linear1 = Linear::new(w1, Some(b1));

        let w2 = Tensor::randn(0.0f32, 0.02, (dim, inner_dim), device)?;
        let b2 = Tensor::zeros((dim,), DType::F32, device)?;
        let linear2 = Linear::new(w2, Some(b2));

        Ok(Self { linear1, linear2, dim })
    }

    fn forward(&self, t: &Tensor, device: &Device) -> Result<Tensor> {
        // Get sinusoidal embedding
        let emb = sinusoidal_embedding(t, self.dim, device)?;

        // MLP: Linear -> SiLU -> Linear
        let emb = self.linear1.forward(&emb)?;
        let emb = silu(&emb)?;
        self.linear2.forward(&emb).map_err(Into::into)
    }
}

/// SiLU (Swish) activation
fn silu(x: &Tensor) -> Result<Tensor> {
    let sigmoid = candle_nn::ops::sigmoid(x)?;
    x.mul(&sigmoid).map_err(Into::into)
}

/// Adaptive Layer Normalization (AdaLN)
struct AdaLayerNorm {
    norm: LayerNorm,
    linear: Linear,
    dim: usize,
}

impl AdaLayerNorm {
    fn new(dim: usize, device: &Device) -> Result<Self> {
        let ln_w = Tensor::ones((dim,), DType::F32, device)?;
        let ln_b = Tensor::zeros((dim,), DType::F32, device)?;
        let norm = LayerNorm::new(ln_w, ln_b, 1e-5);

        // Project conditioning to scale and shift
        let w = Tensor::randn(0.0f32, 0.02, (dim * 2, dim), device)?;
        let b = Tensor::zeros((dim * 2,), DType::F32, device)?;
        let linear = Linear::new(w, Some(b));

        Ok(Self { norm, linear, dim })
    }

    fn forward(&self, x: &Tensor, cond: &Tensor) -> Result<Tensor> {
        // Normalize
        let normalized = self.norm.forward(x)?;

        // Get scale and shift from conditioning
        let params = self.linear.forward(cond)?;
        let chunks = params.chunk(2, D::Minus1)?;
        let scale = chunks.get(0).ok_or_else(|| anyhow::anyhow!("Missing scale chunk"))?;
        let shift = chunks.get(1).ok_or_else(|| anyhow::anyhow!("Missing shift chunk"))?;

        // Apply: scale * normalized + shift
        let scale = (scale + 1.0)?; // Center scale around 1
        normalized.broadcast_mul(&scale)?.broadcast_add(shift).map_err(Into::into)
    }
}

/// Multi-head self-attention
struct MultiHeadAttention {
    q_proj: Linear,
    k_proj: Linear,
    v_proj: Linear,
    out_proj: Linear,
    num_heads: usize,
    head_dim: usize,
    scale: f32,
}

impl MultiHeadAttention {
    fn new(dim: usize, num_heads: usize, device: &Device) -> Result<Self> {
        let head_dim = dim / num_heads;
        let scale = (head_dim as f32).powf(-0.5);

        let init_weight = |dim_out, dim_in| -> Result<Linear> {
            let w = Tensor::randn(0.0f32, 0.02, (dim_out, dim_in), device)?;
            let b = Tensor::zeros((dim_out,), DType::F32, device)?;
            Ok(Linear::new(w, Some(b)))
        };

        Ok(Self {
            q_proj: init_weight(dim, dim)?,
            k_proj: init_weight(dim, dim)?,
            v_proj: init_weight(dim, dim)?,
            out_proj: init_weight(dim, dim)?,
            num_heads,
            head_dim,
            scale,
        })
    }

    fn forward(&self, x: &Tensor) -> Result<Tensor> {
        let (batch, seq_len, _dim) = x.dims3()?;

        // Project Q, K, V
        let q = self.q_proj.forward(x)?;
        let k = self.k_proj.forward(x)?;
        let v = self.v_proj.forward(x)?;

        // Reshape to (batch, num_heads, seq_len, head_dim)
        let q = q.reshape((batch, seq_len, self.num_heads, self.head_dim))?
            .transpose(1, 2)?;
        let k = k.reshape((batch, seq_len, self.num_heads, self.head_dim))?
            .transpose(1, 2)?;
        let v = v.reshape((batch, seq_len, self.num_heads, self.head_dim))?
            .transpose(1, 2)?;

        // Scaled dot-product attention
        let attn = q.matmul(&k.transpose(2, 3)?)?;
        let attn = (attn * self.scale as f64)?;
        let attn = candle_nn::ops::softmax(&attn, D::Minus1)?;

        // Apply attention to values
        let out = attn.matmul(&v)?;

        // Reshape back to (batch, seq_len, dim)
        let out = out.transpose(1, 2)?
            .reshape((batch, seq_len, self.num_heads * self.head_dim))?;

        self.out_proj.forward(&out).map_err(Into::into)
    }
}

/// Feed-forward network
struct FeedForward {
    linear1: Linear,
    linear2: Linear,
}

impl FeedForward {
    fn new(dim: usize, device: &Device) -> Result<Self> {
        let hidden_dim = dim * 4;

        let w1 = Tensor::randn(0.0f32, 0.02, (hidden_dim, dim), device)?;
        let b1 = Tensor::zeros((hidden_dim,), DType::F32, device)?;
        let linear1 = Linear::new(w1, Some(b1));

        let w2 = Tensor::randn(0.0f32, 0.02, (dim, hidden_dim), device)?;
        let b2 = Tensor::zeros((dim,), DType::F32, device)?;
        let linear2 = Linear::new(w2, Some(b2));

        Ok(Self { linear1, linear2 })
    }

    fn forward(&self, x: &Tensor) -> Result<Tensor> {
        let x = self.linear1.forward(x)?;
        let x = x.gelu_erf()?;
        self.linear2.forward(&x).map_err(Into::into)
    }
}

/// DiT Block with AdaLN conditioning
struct DiTBlock {
    norm1: AdaLayerNorm,
    attn: MultiHeadAttention,
    norm2: AdaLayerNorm,
    ff: FeedForward,
}

impl DiTBlock {
    fn new(dim: usize, num_heads: usize, device: &Device) -> Result<Self> {
        Ok(Self {
            norm1: AdaLayerNorm::new(dim, device)?,
            attn: MultiHeadAttention::new(dim, num_heads, device)?,
            norm2: AdaLayerNorm::new(dim, device)?,
            ff: FeedForward::new(dim, device)?,
        })
    }

    fn forward(&self, x: &Tensor, cond: &Tensor) -> Result<Tensor> {
        // Self-attention with AdaLN
        let residual = x.clone();
        let x = self.norm1.forward(x, cond)?;
        let x = self.attn.forward(&x)?;
        let x = (residual + x)?;

        // Feed-forward with AdaLN
        let residual = x.clone();
        let x = self.norm2.forward(&x, cond)?;
        let x = self.ff.forward(&x)?;
        (residual + x).map_err(Into::into)
    }
}

/// Diffusion Transformer for mel spectrogram synthesis
pub struct DiffusionTransformer {
    device: Device,
    config: DiffusionTransformerConfig,
    /// Input projection (mel channels -> hidden)
    input_proj: Option<Linear>,
    /// Content projection
    content_proj: Option<Linear>,
    /// Time embedding
    time_embed: Option<TimestepEmbedding>,
    /// Style projection
    style_proj: Option<Linear>,
    /// Transformer blocks
    blocks: Vec<DiTBlock>,
    /// Final layer norm
    final_norm: Option<LayerNorm>,
    /// Output projection (hidden -> mel channels)
    output_proj: Option<Linear>,
    /// Whether initialized
    weights_loaded: bool,
}

impl DiffusionTransformer {
    /// Create with default config
    pub fn new(device: &Device) -> Result<Self> {
        Self::with_config(DiffusionTransformerConfig::default(), device)
    }

    /// Create with custom config
    pub fn with_config(config: DiffusionTransformerConfig, device: &Device) -> Result<Self> {
        Ok(Self {
            device: device.clone(),
            config,
            input_proj: None,
            content_proj: None,
            time_embed: None,
            style_proj: None,
            blocks: Vec::new(),
            final_norm: None,
            output_proj: None,
            weights_loaded: false,
        })
    }

    /// Load from checkpoint
    pub fn load<P: AsRef<Path>>(path: P, device: &Device) -> Result<Self> {
        let mut dit = Self::new(device)?;
        dit.load_weights(path)?;
        Ok(dit)
    }

    /// Initialize with random weights
    pub fn initialize_random(&mut self) -> Result<()> {
        let dim = self.config.hidden_dim;
        let in_ch = self.config.in_channels;

        // Input projection: mel -> hidden
        let w = Tensor::randn(0.0f32, 0.02, (dim, in_ch), &self.device)?;
        let b = Tensor::zeros((dim,), DType::F32, &self.device)?;
        self.input_proj = Some(Linear::new(w, Some(b)));

        // Content projection: content_dim -> hidden
        let w = Tensor::randn(0.0f32, 0.02, (dim, self.config.content_dim), &self.device)?;
        let b = Tensor::zeros((dim,), DType::F32, &self.device)?;
        self.content_proj = Some(Linear::new(w, Some(b)));

        // Time embedding
        self.time_embed = Some(TimestepEmbedding::new(dim, &self.device)?);

        // Style projection
        if self.config.style_condition {
            let w = Tensor::randn(0.0f32, 0.02, (dim, self.config.style_dim), &self.device)?;
            let b = Tensor::zeros((dim,), DType::F32, &self.device)?;
            self.style_proj = Some(Linear::new(w, Some(b)));
        }

        // Transformer blocks
        self.blocks.clear();
        for _ in 0..self.config.depth {
            self.blocks.push(DiTBlock::new(
                dim,
                self.config.num_heads,
                &self.device,
            )?);
        }

        // Final norm and projection
        let ln_w = Tensor::ones((dim,), DType::F32, &self.device)?;
        let ln_b = Tensor::zeros((dim,), DType::F32, &self.device)?;
        self.final_norm = Some(LayerNorm::new(ln_w, ln_b, 1e-5));

        let w = Tensor::randn(0.0f32, 0.02, (in_ch, dim), &self.device)?;
        let b = Tensor::zeros((in_ch,), DType::F32, &self.device)?;
        self.output_proj = Some(Linear::new(w, Some(b)));

        self.weights_loaded = true;
        Ok(())
    }

    /// Load weights from file
    pub fn load_weights<P: AsRef<Path>>(&mut self, path: P) -> Result<()> {
        let path = path.as_ref();
        if !path.exists() {
            return self.initialize_random();
        }
        self.initialize_random()
    }

    /// Forward pass
    ///
    /// # Arguments
    /// * `x` - Noisy mel spectrogram (batch, seq_len, mel_channels)
    /// * `t` - Timesteps (batch,)
    /// * `content` - Content features from length regulator (batch, seq_len, content_dim)
    /// * `style` - Optional style embedding (batch, style_dim)
    ///
    /// # Returns
    /// * Predicted noise or velocity (batch, seq_len, mel_channels)
    pub fn forward(
        &self,
        x: &Tensor,
        t: &Tensor,
        content: &Tensor,
        style: Option<&Tensor>,
    ) -> Result<Tensor> {
        if !self.weights_loaded {
            // Return placeholder
            return Ok(x.clone());
        }

        let (batch_size, _seq_len, _) = x.dims3()?;

        // Project input mel to hidden dim
        let h = if let Some(ref proj) = self.input_proj {
            proj.forward(x)?
        } else {
            x.clone()
        };

        // Add content features
        let content = if let Some(ref proj) = self.content_proj {
            proj.forward(content)?
        } else {
            content.clone()
        };
        let h = (h + content)?;

        // Get time embedding
        let t_emb = if let Some(ref embed) = self.time_embed {
            embed.forward(t, &self.device)?
        } else {
            Tensor::zeros((batch_size, self.config.hidden_dim), DType::F32, &self.device)?
        };

        // Add style conditioning
        let cond = if self.config.style_condition {
            if let (Some(ref proj), Some(s)) = (&self.style_proj, style) {
                let style_emb = proj.forward(s)?;
                (t_emb + style_emb)?
            } else {
                t_emb
            }
        } else {
            t_emb
        };

        // UViT skip connection storage
        let mut skip_features = Vec::new();
        let mid_point = self.config.depth / 2;

        // First half of transformer blocks (encoder)
        let mut h = h;
        for (_i, block) in self.blocks.iter().take(mid_point).enumerate() {
            h = block.forward(&h, &cond)?;
            if self.config.uvit_skip_connection {
                skip_features.push(h.clone());
            }
        }

        // Second half of transformer blocks (decoder) with skip connections
        for (i, block) in self.blocks.iter().skip(mid_point).enumerate() {
            if self.config.uvit_skip_connection && i < skip_features.len() {
                // Add skip connection from encoder
                let skip_idx = skip_features.len() - 1 - i;
                if skip_idx < skip_features.len() {
                    h = (h + &skip_features[skip_idx])?;
                }
            }
            h = block.forward(&h, &cond)?;
        }

        // Final norm and projection
        let h = if let Some(ref norm) = self.final_norm {
            norm.forward(&h)?
        } else {
            h
        };

        if let Some(ref proj) = self.output_proj {
            proj.forward(&h).map_err(Into::into)
        } else {
            Ok(h)
        }
    }

    /// Get hidden dimension
    pub fn hidden_dim(&self) -> usize {
        self.config.hidden_dim
    }

    /// Get output channels
    pub fn output_channels(&self) -> usize {
        self.config.in_channels
    }

    /// Check if initialized
    pub fn is_initialized(&self) -> bool {
        self.weights_loaded
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_dit_config_default() {
        let config = DiffusionTransformerConfig::default();
        assert_eq!(config.hidden_dim, 512);
        assert_eq!(config.num_heads, 8);
        assert_eq!(config.depth, 13);
        assert_eq!(config.in_channels, 80);
    }

    #[test]
    fn test_sinusoidal_embedding() {
        let device = Device::Cpu;
        let t = Tensor::new(&[0.0f32, 0.5, 1.0], &device).unwrap();
        let emb = sinusoidal_embedding(&t, 64, &device).unwrap();
        assert_eq!(emb.dims(), &[3, 64]);
    }

    #[test]
    fn test_silu() {
        let device = Device::Cpu;
        let x = Tensor::new(&[0.0f32, 1.0, -1.0], &device).unwrap();
        let y = silu(&x).unwrap();
        let values: Vec<f32> = y.to_vec1().unwrap();

        // silu(0) = 0 * sigmoid(0) = 0 * 0.5 = 0
        assert!((values[0] - 0.0).abs() < 0.001);
        // silu(1) = 1 * sigmoid(1) â‰ˆ 0.731
        assert!((values[1] - 0.731).abs() < 0.01);
    }

    #[test]
    fn test_dit_new() {
        let device = Device::Cpu;
        let dit = DiffusionTransformer::new(&device).unwrap();
        assert_eq!(dit.hidden_dim(), 512);
        assert_eq!(dit.output_channels(), 80);
    }

    #[test]
    fn test_dit_placeholder() {
        let device = Device::Cpu;
        let dit = DiffusionTransformer::new(&device).unwrap();

        let x = Tensor::randn(0.0f32, 1.0, (2, 100, 80), &device).unwrap();
        let t = Tensor::new(&[0.5f32, 0.5], &device).unwrap();
        let content = Tensor::randn(0.0f32, 1.0, (2, 100, 512), &device).unwrap();

        let output = dit.forward(&x, &t, &content, None).unwrap();
        assert_eq!(output.dims3().unwrap(), (2, 100, 80));
    }

    #[test]
    fn test_dit_initialized() {
        let device = Device::Cpu;
        let mut dit = DiffusionTransformer::new(&device).unwrap();
        dit.initialize_random().unwrap();

        assert!(dit.is_initialized());

        let x = Tensor::randn(0.0f32, 1.0, (1, 50, 80), &device).unwrap();
        let t = Tensor::new(&[0.5f32], &device).unwrap();
        let content = Tensor::randn(0.0f32, 1.0, (1, 50, 512), &device).unwrap();
        let style = Tensor::randn(0.0f32, 1.0, (1, 192), &device).unwrap();

        let output = dit.forward(&x, &t, &content, Some(&style)).unwrap();
        let (batch, len, channels) = output.dims3().unwrap();
        assert_eq!(batch, 1);
        assert_eq!(len, 50);
        assert_eq!(channels, 80);
    }

    #[test]
    fn test_timestep_embedding() {
        let device = Device::Cpu;
        let embed = TimestepEmbedding::new(256, &device).unwrap();
        let t = Tensor::new(&[0.0f32, 0.5, 1.0], &device).unwrap();
        let emb = embed.forward(&t, &device).unwrap();
        assert_eq!(emb.dims(), &[3, 256]);
    }

    #[test]
    fn test_multi_head_attention() {
        let device = Device::Cpu;
        let attn = MultiHeadAttention::new(256, 8, &device).unwrap();
        let x = Tensor::randn(0.0f32, 1.0, (2, 16, 256), &device).unwrap();
        let out = attn.forward(&x).unwrap();
        assert_eq!(out.dims3().unwrap(), (2, 16, 256));
    }

    #[test]
    fn test_feed_forward() {
        let device = Device::Cpu;
        let ff = FeedForward::new(256, &device).unwrap();
        let x = Tensor::randn(0.0f32, 1.0, (2, 16, 256), &device).unwrap();
        let out = ff.forward(&x).unwrap();
        assert_eq!(out.dims3().unwrap(), (2, 16, 256));
    }
}

---
phase: 02-wav2vec-bert-weights
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/models/semantic/wav2vec_bert.rs
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Wav2Vec-BERT ConvModule processes input through depthwise separable convolution"
    - "FeatureProjection transforms 160-dim input to 1024-dim hidden states"
    - "All 7 conv_module tensors per layer load from checkpoint"
    - "Global feature_projection tensors load from checkpoint"
  artifacts:
    - path: "src/models/semantic/wav2vec_bert.rs"
      provides: "ConvModule struct with forward pass"
      contains: "struct ConvModule"
    - path: "src/models/semantic/wav2vec_bert.rs"
      provides: "FeatureProjection struct with forward pass"
      contains: "struct FeatureProjection"
  key_links:
    - from: "ConvModule::from_tensors"
      to: "encoder.layers.{i}.conv_module.*"
      via: "tensor loading with prefix matching"
      pattern: "conv_module\\.pointwise_conv"
    - from: "FeatureProjection::from_tensors"
      to: "feature_projection.*"
      via: "global tensor loading"
      pattern: "feature_projection\\.projection"
    - from: "EncoderLayer::forward"
      to: "ConvModule::forward"
      via: "conv_module call with residual connection"
      pattern: "conv_module.*forward"
---

<objective>
Implement ConvModule and FeatureProjection for Wav2Vec-BERT encoder

Purpose: The Wav2Vec-BERT checkpoint contains conv_module (7 tensors x 24 layers) and feature_projection (4 tensors global) that are not currently implemented. Without these, the encoder cannot use full pre-trained weights.

Output: Updated wav2vec_bert.rs with ConvModule and FeatureProjection structs that load from HuggingFace checkpoint tensors.
</objective>

<execution_context>
@C:\Users\Henri Smith\.claude-membership/get-shit-done/workflows/execute-plan.md
@C:\Users\Henri Smith\.claude-membership/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-wav2vec-bert-weights/02-CONTEXT.md
@.planning/phases/02-wav2vec-bert-weights/02-RESEARCH.md
@src/models/semantic/wav2vec_bert.rs
@src/models/gpt/conformer.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify checkpoint tensor names and implement ConvModule struct</name>
  <files>src/models/semantic/wav2vec_bert.rs</files>
  <action>
FIRST: Verify checkpoint tensor names exist before implementing structs.
Run diagnostic to enumerate actual tensor names in the Wav2Vec-BERT checkpoint:

```bash
# List tensor names from checkpoint to verify patterns exist
python -c "import safetensors; from safetensors.torch import safe_open; f = safe_open('checkpoints/w2v-bert-2.0/model.safetensors', framework='pt'); print([k for k in f.keys() if 'conv_module' in k or 'feature_projection' in k][:20])"
```

Expected patterns to verify:
- `encoder.layers.0.conv_module.pointwise_conv1.weight`
- `encoder.layers.0.conv_module.depthwise_conv.weight`
- `encoder.layers.0.conv_module.layer_norm.weight`
- `feature_projection.projection.weight`
- `feature_projection.layer_norm.weight`

If tensor names differ from expected, document actual names and adjust implementation accordingly.

THEN: Add ConvModule struct to wav2vec_bert.rs, adapting patterns from conformer.rs. The struct processes:
1. LayerNorm (pre-GLU normalization)
2. Pointwise conv1 (expand 1024 -> 2048 for GLU) - stored as [2048, 1024, 1], reshape to Linear
3. GLU activation (splits 2048 -> 1024)
4. Depthwise conv (kernel=31, groups=1024) - stored as [1024, 1, 31]
5. Depthwise LayerNorm
6. Swish activation (x * sigmoid(x))
7. Pointwise conv2 (1024 -> 1024) - stored as [1024, 1024, 1], reshape to Linear

Key implementation details:
- Copy `swish()` function from conformer.rs (lines 78-82)
- Copy `glu()` function from conformer.rs (lines 84-91)
- Tensor name pattern: `encoder.layers.{i}.conv_module.{component}`
- Pointwise convs have NO bias in checkpoint (use None)
- Depthwise conv: transpose to [batch, channels, seq] before conv1d, transpose back after
- Padding for depthwise: kernel_size / 2 = 15

Add `from_tensors()` constructor that loads:
- layer_norm.weight [1024], layer_norm.bias [1024]
- pointwise_conv1.weight [2048, 1024, 1] -> reshape to [2048, 1024]
- depthwise_conv.weight [1024, 1, 31]
- depthwise_layer_norm.weight [1024], depthwise_layer_norm.bias [1024]
- pointwise_conv2.weight [1024, 1024, 1] -> reshape to [1024, 1024]

Add `new_random()` for fallback and `forward()` that follows the 7-step processing flow.

Use tracing::warn! for any missing tensors (Phase 1 pattern).
  </action>
  <verify>
# Verify checkpoint tensor patterns exist (run BEFORE implementation)
python -c "import safetensors; from safetensors.torch import safe_open; f = safe_open('checkpoints/w2v-bert-2.0/model.safetensors', framework='pt'); keys = [k for k in f.keys() if 'conv_module' in k]; print(f'Found {len(keys)} conv_module tensors'); assert len(keys) > 0, 'No conv_module tensors found!'"

# Verify struct compiles
cargo build --release 2>&1 | grep -E "(error|warning.*conv_module)"
# Should compile with no errors. Warnings about missing conv_module tensors are expected until Task 2.
  </verify>
  <done>
Checkpoint tensor names verified. ConvModule struct exists with from_tensors, new_random, and forward methods. Matches conformer.rs patterns.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement FeatureProjection and wire ConvModule into encoder</name>
  <files>src/models/semantic/wav2vec_bert.rs</files>
  <action>
Add FeatureProjection struct that projects 160-dim input features to 1024-dim hidden states.

Structure:
- layer_norm: LayerNorm [160]
- projection: Linear [1024, 160] (weight) + [1024] (bias)

Tensor names in checkpoint:
- feature_projection.layer_norm.weight [160]
- feature_projection.layer_norm.bias [160]
- feature_projection.projection.weight [1024, 160]
- feature_projection.projection.bias [1024]

Add `from_tensors()` and `new_random()` constructors.
Add `forward()` that applies LayerNorm then Linear.

Wire into SemanticEncoder:
1. Add `feature_projection: Option<FeatureProjection>` field to SemanticEncoder struct
2. In `load_weights()`, load FeatureProjection from tensors
3. In `encode()`, apply feature_projection to input BEFORE encoder layers

Also wire ConvModule into EncoderLayer:
1. Add `conv_module: Option<ConvModule>` field to EncoderLayer struct
2. In `EncoderLayer::from_tensors()`, load ConvModule for each layer
3. In `EncoderLayer::forward()`, call conv_module after attention with residual connection:
   ```rust
   // After attention block
   let hidden = if let Some(ref cm) = self.conv_module {
       (hidden + cm.forward(&hidden)?)?  // residual connection
   } else {
       hidden
   };
   ```

Forward pass order per layer (Conformer-like):
1. Half-step FFN1 with residual (existing)
2. Self-attention with residual (existing)
3. Conv module with residual (NEW - insert here)
4. Half-step FFN2 with residual (existing)
5. Final layer norm (existing)

Use tracing::warn! for missing tensors with component prefix "[Wav2Vec-BERT]".
  </action>
  <verify>
# Must compile with no errors
cargo build --release 2>&1 | grep -E "error"

# Test should pass (uses random weights if checkpoint missing)
cargo test test_semantic_encoder 2>&1

# CRITICAL: Verify ConvModule is actually called in forward() with residual
grep -A 30 'fn forward' src/models/semantic/wav2vec_bert.rs | grep -E 'conv_module.*forward|conv_module\)?'
# Must show conv_module being called in the forward pass
  </verify>
  <done>
FeatureProjection struct exists and is wired into SemanticEncoder.encode(). ConvModule is wired into EncoderLayer.forward() with residual connection. Encoder now follows full Conformer processing flow.
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. Build verification:
```bash
cargo build --release 2>&1 | grep -E "error"
# No errors
```

2. Test verification:
```bash
cargo test semantic 2>&1 | grep -E "(test.*PASSED|test.*FAILED|ok|failed)"
# All semantic tests pass
```

3. Structure verification:
```bash
grep -n "struct ConvModule" src/models/semantic/wav2vec_bert.rs
grep -n "struct FeatureProjection" src/models/semantic/wav2vec_bert.rs
# Both structs exist
```

4. Wiring verification:
```bash
grep -A 30 'fn forward' src/models/semantic/wav2vec_bert.rs | grep 'conv_module'
# ConvModule called in forward pass
```
</verification>

<success_criteria>
- Checkpoint tensor names verified before implementation
- ConvModule struct implements depthwise separable convolution with GLU and Swish
- FeatureProjection struct projects input to hidden dimension
- Both load from HuggingFace checkpoint tensor names
- EncoderLayer.forward() includes conv_module step with residual connection
- SemanticEncoder.encode() applies feature_projection before layers
- All existing tests pass
- Build succeeds with no errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-wav2vec-bert-weights/02-01-SUMMARY.md`
</output>
